name: Scrape Book Data

on:
  workflow_dispatch:
    inputs:
      book_id:
        description: 'The ID of the book to scrape'
        required: true
        default: '2001'
      start_page:
        description: 'The starting page number to scrape from'
        required: false
        default: '1'

jobs:
  scrape-book:
    runs-on: ubuntu-latest
    steps:
    # Step 1: Check out the repository
    - name: Checkout repository
      uses: actions/checkout@v3

    # Step 2: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.11

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4

    # Step 4: Run the scraper
    - name: Run scraper
      run: |
        python src/01-fetch_page_text_all_books_github_actions.py ${{ github.event.inputs.book_id }} --start_page ${{ github.event.inputs.start_page }}

    # Step 5: Pull the latest changes from the repository
    - name: Pull latest changes
      run: git pull origin main

    # Step 6: Add new data, commit, and push
    - name: Commit and push data
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git add data/raw/
        git commit -m "Add scraped data for book_id ${{ github.event.inputs.book_id }}"
        git push origin main
